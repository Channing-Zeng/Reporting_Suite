#!/usr/bin/env python
from time import sleep
import sub_scripts.__check_python_version  # checking for python version and adding site dirs inside

import os
import sys
from os.path import join, isfile
from optparse import OptionParser
from collections import OrderedDict, defaultdict

from source.targetcov import summarize_targetcov
from source.targetcov.summarize_targetcov import get_bed_targqc_inputs
from source.variants import summarize_qc
from source.bcbio_runner import BCBioRunner
from source.config import defaults
from source.logger import info
from source.bcbio_structure import BCBioStructure, process_post_bcbio_args, VariantCaller
from source.prepare_args_and_cnf import add_post_bcbio_args, check_system_resources, set_up_log, set_up_work_dir
from source.variants.vcf_processing import get_trasncripts_fpath
from source.file_utils import safe_mkdir, adjust_path


def main():
    info(' '.join(sys.argv))
    info()
    description = 'This script runs reporting suite on the bcbio final directory.'

    parser = OptionParser(description=description)
    add_post_bcbio_args(parser)

    parser.add_option('--load-mongo', '--mongo-loader', dest='load_mongo', action='store_true', default=defaults['load_mongo'], help='Load to Mongo DB')
    parser.add_option('--datahub-path', dest='datahub_path', help='DataHub directory path to upload final MAFs and CNV (can be remote).')
    parser.add_option('--email', dest='email', help='E-mail address to send notifications on errors and finished jobs.')
    parser.add_option('--reannotate', dest='reannotate', action='store_true', default=False, help='Re-annotate BED file with gene names')
    parser.add_option('--count-dups', dest='count_dups', action='store_true', default=False, help='Count duplicates in coverage metrics')
    parser.add_option('--controls', '-c', dest='controls', help='Optional control sample names for Seq2C. For multiple controls, separate them using :')
    parser.add_option('--seq2c-opts', dest='seq2c_opts', help='Options for the final lr2gene.pl script.')
    parser.add_option('--deep-seq', dest='deep_seq', action='store_true', default=False, help='Use run_info_DeepSeq.yaml')

    cnf, bcbio_project_dirpaths, bcbio_cnfs, final_dirpaths = process_post_bcbio_args(parser)

    cnf_project_name = cnf.project_name
    if len(bcbio_project_dirpaths) > 1:
        cnf.project_name = None

    info()
    info('*' * 70)
    bcbio_structures = []
    for bcbio_project_dirpath, bcbio_cnf, final_dirpath in zip(bcbio_project_dirpaths, bcbio_cnfs, final_dirpaths):
        bcbio_structures.append(BCBioStructure(cnf, bcbio_project_dirpath, bcbio_cnf, final_dirpath, cnf.name))

    # Post-processing one bcbio project as usually
    if len(bcbio_structures) == 1:
        if cnf.min_freq is not None:
            info('Min freq for filtering is %f' % cnf.min_freq)

        if cnf.steps and cnf.load_mongo and 'MongoLoader' not in cnf.steps:
            cnf.steps.append('MongoLoader')

        check_system_resources(cnf, required=['qsub'], optional='transcripts_fpath')

        bcbio_structure = bcbio_structures[0]

        bcbio_runner = BCBioRunner(cnf, bcbio_structure, cnf.bcbio_cnf)
        bcbio_runner.post_jobs()


    # Special case: multiple projects in input. No post-processing them, but rather combining summary reports together.
    elif len(bcbio_structures) > 1:
        if cnf_project_name:
            cnf.project_name = cnf_project_name
        else:
            cnf.project_name = '_'.join([bs.project_name for bs in bcbio_structures])

        if cnf.output_dir is None:
            cnf.output_dir = join(os.getcwd(), cnf.project_name)

        safe_mkdir(cnf.output_dir)

        cnf.log_dir = join(cnf.output_dir, 'log')
        info('log_dirpath: ' + cnf.log_dir)
        safe_mkdir(cnf.log_dir)
        set_up_log(cnf, 'miltiple_projects', cnf.project_name, cnf.output_dir)

        cnf.work_dir = adjust_path(join(cnf.output_dir, 'work'))
        safe_mkdir(cnf.work_dir)

        combine_projects(cnf, bcbio_structures)


def combine_varqc(cnf, bcbio_structures, dirname=BCBioStructure.varqc_dir, name=BCBioStructure.varqc_name):
    callers = []
    samples = []

    for bc in bcbio_structures:
        for vc in bc.variant_callers.values():
            if vc.name not in [c.name for c in callers]:
                callers.append(vc)

    jsons_by_sample_by_caller = defaultdict(dict)
    htmls_by_sample_by_caller = defaultdict(dict)
    for bc in bcbio_structures:
        for vc in bc.variant_callers.values():
            jsons_by_sample_by_caller[vc.name] = vc.find_fpaths_by_sample(dirname, name, 'json', bc.final_dirpath)
            htmls_by_sample_by_caller[vc.name] = vc.find_fpaths_by_sample(dirname, name, 'html', bc.final_dirpath)
            samples.extend(vc.samples)

    output_dir = join(cnf.output_dir, dirname)
    safe_mkdir(output_dir)

    summarize_qc.make_summary_reports(cnf, 1, output_dir,
         callers, samples, jsons_by_sample_by_caller, htmls_by_sample_by_caller)


def combine_projects(cnf, bcbio_structures):
    samples = [s for bs in bcbio_structures for s in bs.samples]

    reuse = cnf.reuse_intermediate
    cnf.reuse_intermediate = True

    combine_varqc(cnf, bcbio_structures, dirname=BCBioStructure.varqc_dir, name=BCBioStructure.varqc_name)
    combine_varqc(cnf, bcbio_structures, dirname=BCBioStructure.varqc_after_dir, name=BCBioStructure.varqc_after_name)

    output_dir = join(cnf.output_dir, BCBioStructure.targqc_summary_dir)
    safe_mkdir(output_dir)
    summarize_targetcov.summarize_targqc(cnf, cnf.threads or len(samples), output_dir, samples)

    cnf.reuse_intermediate = reuse


if __name__ == '__main__':
    main()

