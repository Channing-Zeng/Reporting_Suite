#!/usr/bin/env python
import re
import __check_python_version  # checking for python version and adding site dirs inside

import os
import sys
from optparse import OptionParser
from os.path import join, isfile, basename, isdir, expanduser, exists, dirname, splitext
from time import sleep
import shutil
from collections import OrderedDict
from itertools import dropwhile
import tempfile
from source import BaseSample

from source.calling_process import call
from source.fastqc.fastq_utils import downsample
from source.fastqc.summarize_fastqc import write_fastqc_combo_report
from source.jira_utils import retrieve_jira_info
from source.qsub_utils import submit_job, wait_for_jobs
from source.targetcov.cov import make_targetseq_reports
from source.targetcov.summarize_targetcov import get_bed_targqc_inputs
from source.tools_from_cnf import get_system_path, get_script_cmdline
from source.config import Config
from source.logger import info, critical, err, is_local, warn
from source.prepare_args_and_cnf import add_cnf_t_reuse_prjname_reuse_marker_genome, check_system_resources, determine_sys_cnf, determine_run_cnf, \
    check_genome_resources
from source.file_utils import safe_mkdir, verify_dir, verify_file, make_tmpfile, adjust_system_path, adjust_path
from source.utils import compatible_with_ngs_webserver
from source.webserver.ssh_utils import symlink_to_ngs, sync_with_ngs_server


NGS_WEBSERVER_SEQQC_DIR = '/opt/lampp/htdocs/seqQC'
if is_local():
    NGS_WEBSERVER_SEQQC_DIR = '/Users/vladsaveliev/Sites/seqQC'


def proc_opts():
    info(' '.join(sys.argv))
    info()
    description = 'This script runs preprocessing.'

    parser = OptionParser(description=description)
    add_cnf_t_reuse_prjname_reuse_marker_genome(parser)
    parser.add_option('-j', '--jira', dest='jira', help='JIRA case path (goes to the ngs-website)')
    parser.add_option('-e', '--expose', dest='expose_to_ngs_server', action='store_true', default=False, help='Add project to the webserver')
    parser.add_option('--expose-only', dest='expose_to_ngs_server_only', action='store_true', default=False, help='Only add project to the webserver')
    # parser.add_option('--datahub-path', dest='datahub_path', help='DataHub directory path to upload final MAFs and CNV (can be remote).')
    # parser.add_option('--reporter', dest='reporter', help='Reporter name (goes to the ngs-website).')

    (opts, args) = parser.parse_args()
    if len(args) < 2:  # /ngs/oncology/datasets/hiseq/150521_D00443_0159_AHK2KTADXX/Unalign/fastq/fastqc
        critical('Usage: ' + __file__ + ' <dataset/location/dir> <project_name> [--jira URL] [--expose]')

    # base_dirpath = verify_dir(join(DATASETS_ROOT_DIRPATH, args[0]), is_critical=True)
    dataset_dirpath = verify_dir(args[0])
    project_name = args[1]
    # dataset_dirpath = verify_dir(join(base_dirpath, project_name), is_critical=True)
    jira_url = args[2] if len(args) > 2 else None

    cnf = Config(opts.__dict__, determine_sys_cnf(opts), determine_run_cnf(opts))
    # check_genome_resources(cnf)
    check_system_resources(cnf, optional=['fastq'])
    check_genome_resources(cnf)

    work_dir_path = tempfile.mkdtemp(dir=expanduser('~'))
    # work_dir_path =  #join(dataset_dirpath, 'work')
    safe_mkdir(work_dir_path)
    cnf.work_dir = join(work_dir_path, 'pre_processing')
    safe_mkdir(cnf.work_dir)
    cnf.log_dir = join(cnf.work_dir, 'log')
    safe_mkdir(cnf.log_dir)

    cnf.project_name = project_name
    info('Project name: ' + cnf.project_name)

    return cnf, dataset_dirpath, jira_url


# def __parse_sample_sheet(sample_sheet_fpath):
#     with open(sample_sheet_fpath) as f:
#         sample_lines = dropwhile(lambda l: not l.startswith('FCID'), f)
#         sample_infos = []
#         keys = []
#         for l in sample_lines:
#             if l.startswith('FCID'):
#                 keys = l.strip().split(',')
#             else:
#                 fs = l.strip().split(',')
#                 sample_infos.append(dict(zip(keys, fs)))
#
#     sample_names = []
#     for i, info_d in enumerate(sample_infos):
#         key = 'Sample_ID'
#         if key not in info_d:
#             key = 'SampleID'
#         lane = 1
#         if 'Lane' in info_d:
#             lane = int(info_d['Lane'])
#         sample_names.append(info_d[key].replace(' ', '_'))
#         # sample_names.append(info_d[key].replace(' ', '-') + '_' + info_d['Index'] + '_L%03d' % lane)
#         # sample_names.append(info_d[key].replace(' ', '-').replace('_', '-') + '_S' + str(i + 1) + '_L001')
#
#     return sample_names


def main():
    cnf, project_dirpath, jira_url = proc_opts()

    unaligned_dirpath = join(project_dirpath, 'Unalign')
    verify_dir(unaligned_dirpath, description='Unalign dir', is_critical=True)

    # Reading project name
    bcl2fastq_dirpath = None
    try:
        bcl2fastq_dirpath = join(unaligned_dirpath, next(fn for fn in os.listdir(unaligned_dirpath) if fn.startswith('Project_')))
    except StopIteration:
        critical('Could not find directory starting with Project_ in ' + unaligned_dirpath)
    cnf.project_name = cnf.project_name or bcl2fastq_dirpath.split('Project_')[1]

    # Parsing sample sheet
    basecalls_dirpath = join(project_dirpath, 'Data/Intensities/BaseCalls')
    verify_dir(basecalls_dirpath, is_critical=True)
    sample_sheet_csv_fpath = join(basecalls_dirpath, 'SampleSheet.csv')
    if not isfile(sample_sheet_csv_fpath):
        sample_sheet_csv_fpath = join(project_dirpath, 'SampleSheet.csv')
    verify_file(sample_sheet_csv_fpath, is_critical=True)

    # Directory to run fastq
    fastq_dirpath = join(unaligned_dirpath, 'fastq')
    safe_mkdir(fastq_dirpath)
    sample_dirpaths = [join(bcl2fastq_dirpath, sample_dirname)
                       for sample_dirname in os.listdir(bcl2fastq_dirpath)
                       if isdir(join(bcl2fastq_dirpath, sample_dirname))]
    samples = []
    for sample_dirpath in sample_dirpaths:
        sample_dirname = basename(sample_dirpath)
        if sample_dirname.startswith('Sample_'):
            sample_name = sample_dirname.split('_', 1)[1]
            r1_fpath = __find_and_concat_fastq(sample_dirpath, sample_name, fastq_dirpath, 'R1')
            r2_fpath = __find_and_concat_fastq(sample_dirpath, sample_name, fastq_dirpath, 'R2')
            samples.append(Sample(sample_name, r1_fpath, r2_fpath))

    # Write sample and fastq list
    # sample_list_fpath = join(fastq_dirpath, 'samples.list')
    # verify_file(sample_list_fpath, is_critical=True)
    # with open(sample_list_fpath) as f:
    #     sample_names = [l.strip() for l in f]

    # Downsample, align, and analyse
    bam_by_sample = dict()
    for sample in samples:
        l_fpath, r_fpath = downsample_fastq(cnf, sample)
        bam_by_sample[sample.name] = align(cnf, sample, l_fpath, r_fpath)

    downsample_metamapping_dirpath = join(project_dirpath, 'Downsample_MetaMapping')
    safe_mkdir(downsample_metamapping_dirpath)
    run_metamapping(cnf, samples, bam_by_sample, downsample_metamapping_dirpath)

    downsample_targqc_dirpath = join(project_dirpath, 'Downsample_TargQC')
    safe_mkdir(downsample_targqc_dirpath)
    run_targqc(cnf, samples, bam_by_sample, downsample_targqc_dirpath)

    # Running FastQC
    fastqc_dirpath = join(fastq_dirpath, 'fastqc')
    safe_mkdir(fastqc_dirpath)
    comb_fastqc_fpath = join(fastqc_dirpath, 'FastQC.html')
    if not cnf.expose_to_ngs_server_only:
        make_fastqc_reports(cnf, samples, fastq_dirpath, fastqc_dirpath, comb_fastqc_fpath)

    # Creating symlink new project-name directory in Datasets
    new_project_symlink = join(dirname(project_dirpath), cnf.project_name)
    if not exists(new_project_symlink):
        os.symlink(project_dirpath, new_project_symlink)

    # Exposing
    if compatible_with_ngs_webserver() and (cnf.expose_to_ngs_server or cnf.expose_to_ngs_server_only):
        # FastQC
        ngs_webserver_seqqc_proj_dirpath = join(NGS_WEBSERVER_SEQQC_DIR, cnf.project_name)
        if symlink_to_ngs(comb_fastqc_fpath, ngs_webserver_seqqc_proj_dirpath) is None:
            err('Error: cannot connect to the ngs server and make symlinks')
        else:
            # BaseCalls
            basecall_stats_dirnames = [fname for fname in os.listdir(basecalls_dirpath) if fname.startswith('Basecall_Stats_')]
            if len(basecall_stats_dirnames) > 1:
                err('More than 1 Basecall_Stats_* dirs found in unalign_dirpath')
            if len(basecall_stats_dirnames) == 0:
                err('No Basecall_Stats_* dirs found in unalign_dirpath')
            if len(basecall_stats_dirnames) == 1:
                basecall_stats_dirpath = join(basecalls_dirpath, basecall_stats_dirnames[0])
                fpaths = filter(None, (verify_file(join(basecall_stats_dirpath, html_fname) for html_fname in ['Demultiplex_Stats.htm', 'All.htm', 'IVC.htm'])))
                symlink_to_ngs(fpaths, ngs_webserver_seqqc_proj_dirpath)

            # Sample sheet
            symlink_to_ngs(sample_sheet_csv_fpath, ngs_webserver_seqqc_proj_dirpath)

        jira_case = None
        if jira_url:
            # Add to the NGS list
            jira_case = retrieve_jira_info(jira_url)

        sync_with_ngs_server(cnf, jira_case=jira_case,
            project_name=cnf.project_name, sample_names=[s.name for s in samples])

    info()
    info('*' * 70)


def __find_and_concat_fastq(sample_dirpath, sample_name, fastq_dirpath, suf='R1'):
    fastq_fpaths = [join(sample_dirpath, fn) for fn in os.listdir(sample_dirpath) if re.match(sample_name + '.*_' + suf + '.*\.fastq\.gz', fn)]
    if not fastq_fpaths:
        critical('No fastq files for the sample ' + sample_name + ' were found inside ' + sample_dirpath)

    concat_fastq_fpath = join(fastq_dirpath, sample_name + '_' + suf + '.fastq.gz')
    with open(concat_fastq_fpath, 'w') as out:
        for fq_fpath in fastq_fpaths:
            with open(fq_fpath, 'r') as inp:
                shutil.copyfileobj(inp, out)
    return concat_fastq_fpath


def downsample_fastq(cnf, sample, reads_num=1e6):
    # downsampled_reads_fpath = join(cnf.work_dir, sample.name + '_' + str(reads_num) + '.fastq')
    info('Downsampling ' + sample.name + ' to ' + str(int(reads_num)))
    l_fpath, r_fpath = downsample(cnf.work_dir, sample.l_fpath, sample.r_fpath, int(reads_num))
    return l_fpath, r_fpath


def align(cnf, sample, l_fpath, r_fpath):
    ref = cnf.genome.seq
    bwa = get_system_path(cnf, 'bwa')
    bwa_cmdline = '{bwa} mem {ref} {l_fpath} {r_fpath}'.format(**locals())
    sam_fpath = join(cnf.work_dir, sample.name + '_downsampled.sam')
    call(cnf, bwa_cmdline, output_fpath=sam_fpath)

    samtools = get_system_path(cnf, 'samtools')
    bam_fpath = join(cnf.work_dir, sample.name + '_downsampled.bam')
    sam2bam_cmdline = '{samtools} view -Sb {sam_fpath}'.format(**locals())
    call(cnf, sam2bam_cmdline, output_fpath=bam_fpath)

    return bam_fpath


def run_metamapping(cnf, samples, bam_by_sample, output_dirpath):
    info('Running MetaMapping for downsampled BAMs')


def run_targqc(cnf, samples, bam_by_sample, output_dirpath):
    info('Running TargQC for downsampled BAMs')

    exons_bed_fpath = adjust_path(cnf.exons) if cnf.exons else adjust_path(cnf.genome.exons)
    bed_fpath = cnf.bed
    if bed_fpath:
        info('Using amplicons/capture panel ' + bed_fpath)
    elif exons_bed_fpath:
        info('WGS, taking CDS as target')

    for sample in samples:
        sample.bed = cnf.bed
        sample.bam = bam_by_sample[sample.name]
        output_dirpath = join(output_dirpath, sample.name)
        safe_mkdir(output_dirpath)
        info('Running targeqSeq for ' + sample.name + ', saving into ' + output_dirpath)
        avg_depth, gene_by_name, reports = make_targetseq_reports(
            cnf, output_dirpath, sample, exons_bed_fpath)
        [summary_report, per_gene_report] = reports
        info()


def run_fastqc(cnf, sample, fastqc_dirpath, need_downsample=True):
    # with tx_tmpdir(fastqc_work_dir, fastqc_dirpath) as fastqc_out_tx_dirpath:
    cmdline = get_script_cmdline(cnf, 'python', join('scripts', 'pre', 'fastqc.py'))
    cmdline += (' --sys-cnf {cnf.sys_cnf} --sample {sample.name} -1 {sample.l_fpath} -2 {sample.r_fpath} -o {fastqc_dirpath}'.format(**locals()))
    return submit_job(cnf, cmdline, 'FastQC_' + sample.name)

    # parser = FastQCParser(fastqc_out, data["name"][-1])
    # stats = parser.get_fastqc_summary()
    # parser.save_sections_into_file()


class Sample():
    def __init__(self, name, l_fpath, r_fpath):
        self.name = name
        self.l_fpath = l_fpath
        self.r_fpath = r_fpath
        self.fastqc_html_fpath = None
        self.bam = None
        self.bed = None


def find_fastq_pairs_by_sample_name(fastq_fpaths, samples_names):
    fastq_by_sn = OrderedDict()

    for sn in samples_names:
        sn_fastq_fpaths = sorted([f for f in fastq_fpaths if basename(f).startswith(sn + '_R')])
        if len(sn_fastq_fpaths) == 0:
            err('Error: no fastq found for ' + sn)
            fastq_by_sn[sn] = None
        elif len(sn_fastq_fpaths) > 2:
            critical('Error: more than 2 fastq files starting with ' + sn + '_R: ' + ', '.join(sn_fastq_fpaths))
        elif len(sn_fastq_fpaths) == 1:
            warn('Warning: only single fastq file is found for ' + sn + '. Treating as single reads.')
            fastq_by_sn[sn] = [verify_file(sn_fastq_fpaths[0]), None]
        else:
            fastq_by_sn[sn] = [verify_file(fpath) for fpath in sn_fastq_fpaths]

    return fastq_by_sn


def make_fastqc_reports(cnf, samples, fastq_dirpath, fastqc_dirpath, comb_fastqc_fpath):
    if isdir(fastqc_dirpath):
        if isdir(fastqc_dirpath + '.bak'):
            try:
                shutil.rmtree(fastqc_dirpath + '.bak')
            except OSError:
                pass
        if not isdir(fastqc_dirpath + '.bak'):
            os.rename(fastqc_dirpath, fastqc_dirpath + '.bak')
    if isdir(fastqc_dirpath):
        err('Could not run and combine fastqc because it already exists and could not be moved to fastqc.bak')
        return None

    fastqc = get_system_path(cnf, 'fastqc')
    if not fastqc:
        err('FastQC is not found, cannot make reports')
        return None

    else:
        safe_mkdir(fastqc_dirpath)
        fastqc_jobs = []
        for sample in samples:
            j = run_fastqc(cnf, sample, fastqc_dirpath)
            info()
            fastqc_jobs.append(j)
        wait_for_jobs(fastqc_jobs)

        for s in samples:
            sample_fastqc_dirpath = join(fastqc_dirpath, s.name + '.fq_fastqc')
            try:
                os.remove(sample_fastqc_dirpath)
            except OSError:
                pass
            s.fastqc_html_fpath = join(fastqc_dirpath, s.name + '.fq_fastqc.html')
            verify_file(s.fastqc_html_fpath, is_critical=True, silent=True)
            if os.path.exists(sample_fastqc_dirpath + '.zip'):
                safe_mkdir(join(fastqc_dirpath, 'zip'))
                os.rename(sample_fastqc_dirpath + '.zip', join(fastqc_dirpath, 'zip'))

        write_fastqc_combo_report(comb_fastqc_fpath, samples)
        verify_file(comb_fastqc_fpath, is_critical=True)
        info('Combined FastQC saved to ' + comb_fastqc_fpath)
        return comb_fastqc_fpath


if __name__ == '__main__':
    main()


'''
#!/bin/bash/

#Takes 2 arguements, data_loc and project_name, as created in datasets, such as hiseq and Dev_0200_HiSeq_DS
#Usage - upload_seqQC.sh hiseq Dev_0200_HiSeq_DS https://jira.rd.astrazeneca.net/browse/NGSG-313
#Usage - upload_seqQC.sh bioscience Bio_0041_IDT_RR_DS

datasets=/ngs/oncology/datasets
data_loc=$1
project_name=$2

cd /opt/lampp/htdocs/seqQC/
#echo "In /opt/lampp/htdocs/seqQC on NGS Server"
echo " "

mkdir $project_name
cd $project_name
mkdir FastQC

echo "Demultiplex Report linked!"
echo " "

echo "SampleSheet linked!"
echo "DONE!"
echo " "

'''